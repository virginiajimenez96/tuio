{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e32ed64",
   "metadata": {},
   "source": [
    "# **Exercise 3: Predictive Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "cc24a69b-d08d-4b54-be8c-edde66865493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630943ba",
   "metadata": {},
   "source": [
    "### 1. Function to load data from PostgreSQL, merge datasets and identify target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "e5a30d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_postgresql_data(db_url):\n",
    "\n",
    "    print(\"Connecting to PostgreSQL...\")\n",
    "    engine = create_engine(db_url)\n",
    "\n",
    "    customers = pd.read_sql(\"SELECT * FROM customers\", con=engine)\n",
    "    policies = pd.read_sql(\"SELECT * FROM policies\", con=engine)\n",
    "    claims = pd.read_sql(\"SELECT * FROM claims\", con=engine)\n",
    "    risk_indicators = pd.read_sql(\"SELECT * FROM risk_indicators\", con=engine)\n",
    "\n",
    "    print(\"Data loaded successfully!\")\n",
    "\n",
    "    # merge datasets\n",
    "    df = policies.merge(customers, on=\"customer_id\", how=\"left\")\n",
    "    df = df.merge(risk_indicators, on=\"customer_id\", how=\"left\")\n",
    "\n",
    "    # our target => claim in the last year\n",
    "    recent_claims = claims[claims[\"claim_date\"] >= \"2024-01-01\"]\n",
    "    df[\"target\"] = df[\"customer_id\"].isin(recent_claims[\"customer_id\"]).astype(int)\n",
    "\n",
    "    print(df.info())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61309626",
   "metadata": {},
   "source": [
    "### 2. Function to identify features, transform dataset and define transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "85b9a6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "\n",
    "    # separate categorical and numerical features\n",
    "    categorical_features = [\"policy_type\", \"state\"]\n",
    "    numerical_features = [\n",
    "        \"property_risk_score\",\n",
    "        \"health_risk_score\",\n",
    "        \"driving_violations\",\n",
    "    ]\n",
    "\n",
    "    # drop not used columns\n",
    "    df.drop(\n",
    "        columns=[\n",
    "            \"customer_id\",\n",
    "            \"policy_id\",\n",
    "            \"created_at\",\n",
    "            \"customer_name\",\n",
    "            \"email\",\n",
    "            \"phone_number\",\n",
    "        ],\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    # define transformers\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", StandardScaler(), numerical_features),\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_features),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return df, preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bb302f",
   "metadata": {},
   "source": [
    "### 3. Function to train and evaluate the models (with and without parameters tunning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "5648956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X_train, X_test, y_train, y_test, preprocessor, models, param_grids=None):\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        pipeline = Pipeline(\n",
    "            steps=[(\"preprocessor\", preprocessor), (\"classifier\", model)]\n",
    "        )\n",
    "        if param_grids and name in param_grids:\n",
    "            print(f\"Tuning hyperparameters for {name}...\")\n",
    "            grid_search = GridSearchCV(\n",
    "                pipeline, param_grids[name], scoring=\"roc_auc\"\n",
    "            )\n",
    "            grid_search.fit(X_train, y_train)\n",
    "\n",
    "            print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
    "            pipeline = grid_search.best_estimator_\n",
    "        else:\n",
    "            pipeline.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        y_pred_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # evaluate models using different metrics\n",
    "        precision = classification_report(y_test, y_pred, output_dict=True)[\"1\"][\n",
    "            \"precision\"\n",
    "        ]\n",
    "        recall = classification_report(y_test, y_pred, output_dict=True)[\"1\"][\"recall\"]\n",
    "        f1 = classification_report(y_test, y_pred, output_dict=True)[\"1\"][\"f1-score\"]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "        results[name] = {\n",
    "            \"Precision\": round(precision, 3),\n",
    "            \"Recall\": round(recall, 3),\n",
    "            \"F1-Score\": round(f1, 3),\n",
    "            \"ROC-AUC\": round(roc_auc, 3),\n",
    "        }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f9a850",
   "metadata": {},
   "source": [
    "### 4. Load postgreSQL credentials from config file and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "b5088633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to PostgreSQL...\n",
      "Data loaded successfully!\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 995 entries, 0 to 994\n",
      "Data columns (total 17 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   policy_id            995 non-null    object        \n",
      " 1   customer_id          995 non-null    object        \n",
      " 2   policy_type          995 non-null    object        \n",
      " 3   created_at           995 non-null    datetime64[ns]\n",
      " 4   customer_name        995 non-null    object        \n",
      " 5   date_of_birth        995 non-null    datetime64[ns]\n",
      " 6   phone_number         995 non-null    object        \n",
      " 7   email                995 non-null    object        \n",
      " 8   street_address       995 non-null    object        \n",
      " 9   state                995 non-null    object        \n",
      " 10  post_code            995 non-null    object        \n",
      " 11  iban                 995 non-null    object        \n",
      " 12  job                  995 non-null    object        \n",
      " 13  driving_violations   995 non-null    float64       \n",
      " 14  property_risk_score  995 non-null    float64       \n",
      " 15  health_risk_score    995 non-null    float64       \n",
      " 16  target               995 non-null    int64         \n",
      "dtypes: datetime64[ns](2), float64(3), int64(1), object(11)\n",
      "memory usage: 132.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "with open(\"../config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "    db_name = config[\"DB_NAME\"]\n",
    "    db_user = config[\"DB_USER\"]\n",
    "    db_password = config[\"DB_PASSWORD\"]\n",
    "    db_host = config[\"DB_HOST\"]\n",
    "    db_port = int(config[\"DB_PORT\"])\n",
    "\n",
    "DB_URL = f\"postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}\"\n",
    "engine = create_engine(DB_URL)\n",
    "#load data, merge datasets and create target column\n",
    "df = load_postgresql_data(DB_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4c9fbc",
   "metadata": {},
   "source": [
    "### 5. Prepare dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "25909457",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, preprocessor = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fb5af1",
   "metadata": {},
   "source": [
    "### 6. Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "6feceaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"target\"])\n",
    "y = df[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=5, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f44fac",
   "metadata": {},
   "source": [
    "### 7. Train models (logistic regression, random forest and XGBoost) with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "ac532df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Comparison using default parameters:\n",
      "                     Precision  Recall  F1-Score  ROC-AUC\n",
      "Logistic Regression      0.537   0.483     0.509    0.579\n",
      "Random Forest            0.833   0.674     0.745    0.859\n",
      "XGBoost                  0.758   0.843     0.798    0.864\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=15),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=6),\n",
    "}\n",
    "\n",
    "model_results = train_models(X_train, X_test, y_train, y_test, preprocessor, models)\n",
    "results_df = pd.DataFrame(model_results).T\n",
    "print(\"Model Comparison using default parameters:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460ddbd1",
   "metadata": {},
   "source": [
    "### 8. Train best models (Random forest and XGBoost) with tunned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "f230d094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning hyperparameters for Random Forest...\n",
      "Best parameters for Random Forest: {'classifier__max_depth': 30, 'classifier__n_estimators': 200}\n",
      "Tuning hyperparameters for XGBoost...\n",
      "Best parameters for XGBoost: {'classifier__learning_rate': 0.2, 'classifier__max_depth': 15, 'classifier__n_estimators': 200}\n",
      "Model Comparison using tunned parameters:\n",
      "               Precision  Recall  F1-Score  ROC-AUC\n",
      "Random Forest      0.793    0.82     0.807    0.918\n",
      "XGBoost            0.880    0.91     0.895    0.949\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "}\n",
    "param_grids = {\n",
    "    \"Random Forest\": {\n",
    "        \"classifier__n_estimators\": [100, 150, 200],\n",
    "        \"classifier__max_depth\": [20, 25, 30]\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"classifier__n_estimators\": [100, 150, 200],\n",
    "        \"classifier__learning_rate\": [0.1, 0.2, 0.3],\n",
    "        \"classifier__max_depth\": [5, 10, 15],\n",
    "    },\n",
    "}\n",
    "model_results = train_models(X_train, X_test, y_train, y_test, preprocessor, models, param_grids)\n",
    "results_df = pd.DataFrame(model_results).T\n",
    "print(\"Model Comparison using tunned parameters:\")\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
